{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting categories with Naive Bayes & SVMS\n",
    "\n",
    "**Aim**: The aim of this notebook is to provide code-based examples for the implementation of the Naive Bayes & Linear Support Vector Machines using scikit-learn. \n",
    "\n",
    "## Table of contents \n",
    "\n",
    "1. Naive Bayes Classifier\n",
    "2. Linear Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fraud_prediction.csv')\n",
    "\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "#Creating the features \n",
    "\n",
    "features = df.drop('isFraud', axis = 1).values\n",
    "target = df['isFraud'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data into training & test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42, \n",
    "                                                    stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Naive Bayes Clssifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing an NB classifier\n",
    "\n",
    "nb_classifier = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the classifier into the training data\n",
    "\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the accuracy score from the base classifier\n",
    "\n",
    "nb_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fraud_prediction.csv')\n",
    "\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "#Creating the features \n",
    "\n",
    "features = df.drop('isFraud', axis = 1).values\n",
    "target = df['isFraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42, \n",
    "                                                    stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the linear SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing a SVM model \n",
    "\n",
    "svm = LinearSVC(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model to the training data\n",
    "\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the accuracy score from the training data\n",
    "\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphical hyper-parameter optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores = []\n",
    "testing_scores = []\n",
    "\n",
    "param_list = [0.0001, 0.001, 0.01, 0.1, 10, 100, 1000]\n",
    "\n",
    "# Evaluate the training and test classification errors for each value of the parameter\n",
    "\n",
    "for param in param_list:\n",
    "    \n",
    "    # Create SVM object and fit\n",
    "    \n",
    "    svm = LinearSVC(C = param, random_state = 42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the accuracy scores and append to lists\n",
    "    \n",
    "    training_scores.append(svm.score(X_train, y_train) )\n",
    "    testing_scores.append(svm.score(X_test, y_test) )\n",
    "    \n",
    "# Plot results\n",
    "\n",
    "plt.semilogx(param_list, training_scores, param_list, testing_scores)\n",
    "plt.legend((\"train\", \"test\"))\n",
    "plt.ylabel('Accuracy scores')\n",
    "plt.xlabel('C (Inverse regularization strength)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-parameter optimization using GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model \n",
    "\n",
    "svm = LinearSVC(random_state = 50)\n",
    "\n",
    "#Using GridSearchCV to search for the best parameter\n",
    "\n",
    "grid = GridSearchCV(svm, {'C':[0.00001, 0.0001, 0.001, 0.01, 0.1, 10]})\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print out the best parameter\n",
    "\n",
    "print(\"The best value of the inverse regularization strength is:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the scaling pipeline \n",
    "\n",
    "order = [('scaler', StandardScaler()), ('SVM', LinearSVC(C = 0.1, random_state = 50))]\n",
    "\n",
    "pipeline = Pipeline(order)\n",
    "\n",
    "#Fitting the classfier to the scaled dataset \n",
    "\n",
    "svm_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Extracting the score \n",
    "\n",
    "svm_scaled.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
